
** Introduction
   PyTorch is a flexible deep learning framework, which enables you to make custom LSTM cells. However, custom LSTM cells cannot exploit the convenient options provided by [[https://pytorch.org/docs/1.1.0/nn.html#torch.nn.LSTM][PyTorch's standard LSTM]], including:
   - Bidirection
   - Multi-layers
   - Dropout
   Therefore, it is tedious to implement all such options from scratch.

   Here, I made a simple LSTM package which eases the cumbersome by ~LSTMFrame~. Also, the package provides ~LayerNormLSTM~, a LSTM variant including [[https://arxiv.org/pdf/1607.06450.pdf][layer normalization]] and [[https://arxiv.org/pdf/1603.05118.pdf][recurrent dropout]] as options.

** Requirement
   It needs PyTorch-1.1 or more recent version.

** Document
   Important classes are described as follows:
   - ~LSTMFrame~: It is a general framework to customize LSTMs. Its ~forward~ provides the same API with that of [[https://pytorch.org/docs/1.1.0/nn.html#torch.nn.LSTM][LSTM]] when given a list of LSTM cells to its ~__init__~. The list depicts the LSTM's layout. For example, it needs [(~cell_0f, cell_0b~), (~cell_1f, cell_1b~)] to get a bidirectional and two-layer LSTM.  Also, you can set the options of _dropout_ and _bidirection_.
     *Caution*: It can process a batch with variable-length sequences (just by converting [[https://pytorch.org/docs/stable/nn.html#torch.nn.utils.rnn.PackedSequence][PackedSequence]] object to a tensor and lengths), but the computation time is proportional to the maximum length of input sequences for each batch.
   - ~LayerNormLSTMCell~: An example of custom LSTM cell where [[https://arxiv.org/pdf/1607.06450.pdf][layer normalization]] and [[https://arxiv.org/pdf/1603.05118.pdf][recurrent dropout]] are applied. The implementation is based on [[https://www.tensorflow.org/api_docs/python/tf/contrib/rnn/LayerNormBasicLSTMCell][tf.contrib.rnn.LayerNormBasicLSTMCell]].
   - ~LayerNormLSTM~: An application of ~LSTMFrame~ with ~LayerNormLSTMCell~. The class provides the key options of [[https://pytorch.org/docs/1.1.0/nn.html#torch.nn.LSTM][LSTM]] and additional options, ~r_dropout~ for [[https://arxiv.org/pdf/1603.05118.pdf][recurrent dropout]] and ~layer_norm_enabled~ for [[https://arxiv.org/pdf/1607.06450.pdf][layer normalization]].
     
   Also, you can check [[https://github.com/daehwannam/pytorch-rnn-util/blob/master/example.py][example.py]] to understand the usage of ~LSTMFrame~ and ~LayerNormLSTM~.

** Note
   ~LSTMFrame~ is not exhaustively tested for various options. So, I recommend to use [[https://pytorch.org/docs/1.1.0/nn.html#torch.nn.LSTM][standard LSTM]] first then replace it with this package later.
